{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0FydRedUP27"
      },
      "source": [
        "# Turning a Google Colab notebook into a web app\n",
        "\n",
        "---\n",
        "\n",
        "### This notebook is designed to be used alongside Anvil's [turning a Colab notebook into a web app tutorial](https://anvil.works/learn/tutorials/google-colab-to-web-app).\n",
        "\n",
        "The text cells below tell you the steps you need to take to connect this notebook to an Anvil app. The steps are:\n",
        "\n",
        "\n",
        "1. Install the `anvil-uplink` library\n",
        "2. Import the `anvil.server` package\n",
        "3. Connect the notebook using your apps Uplink key\n",
        "4. Create a function to call from your app that includes the `anvil.server.callable` decorator\n",
        "5. Add `anvil.server.wait_forever()` to the end of the notebook\n",
        "\n",
        "### Follow along below for more detail.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRNEq2Tb5gnq"
      },
      "source": [
        "### Let's start by installing the `anvil-uplink` library, all we need to do is add `!pip install anvil-uplink` to the first cell of the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMlpRGFd14C1",
        "outputId": "6be09179-9271-4140-9c6a-1d8ba02cab66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (12.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155202 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "#실행 후 runtime 다시 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc5hg4Mtz-pS",
        "outputId": "1b20e1ba-bc80-480d-d986-967dfc2ec210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.2.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=9dc80dff2d3e06adcd098c736243c65d963820d32ea6e2bb02edd05556d1841b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "5BvNgFgk5dE2",
        "outputId": "d9e858a4-c653-4661-880d-3867335a3fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.3.42-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting ws4py\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 30 kB 41.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 40 kB 41.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 51 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 195 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=699a9f301390fbaf52858bd4e7946c04146a03ab9d59cb32ce575da4fed7e59a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.42 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOjHWnhO5k0x"
      },
      "source": [
        "### Next import the Anvil server package by adding `import anvil.server`:\n",
        "\n",
        "Importing `anvil.server` means, when this notebook is connected via the Uplink, it will behave in the same way as any other [Anvil Server Module](https://anvil.works/docs/server)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EML6wBYQ5fiM"
      },
      "outputs": [],
      "source": [
        "import anvil.server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cuHx3s3Vm52"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV2ze8a7ScHo"
      },
      "source": [
        "### Then connect this notebook to your app using your Uplink key `anvil.server.connect(\"your-uplink-key\")`:\n",
        "\n",
        "For information on how to get your apps Uplink key, see [Step 4 - Enable the Uplink](https://anvil.works/learn/tutorials/google-colab-to-web-app#step-4-enable-the-uplink)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA9-qSCOSckw",
        "outputId": "43f726fa-625c-4746-b019-ce95129b38b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "anvil.server.connect(\"WOPDH2O4RB53RMBRPRO2MB6D-4SZNPSZA5HU5ZY36\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlf9a7vM_PVF"
      },
      "source": [
        "### Build and train the classification model\n",
        "\n",
        "The next cell gets the dataset, finds an optimal number of neighbours and then builds and trains the model. How this works is outside the scope of this tutorial, however, if you want to read more about how the code below works, Towards Data Science has a useful article [here](https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75).\n",
        "\n",
        "#### *We don't need to change anything in the next cell.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9FGGe-2-V79"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn import metrics\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# import anvil.server\n",
        "# import anvil.media\n",
        "# from datetime import date\n",
        "\n",
        "# iris = load_iris()\n",
        "# X = iris.data\n",
        "# y = iris.target\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=4)\n",
        "\n",
        "# # The following code is used only when needing to find the optimal n_neighbors\n",
        "# \"\"\"\n",
        "# scores = {}\n",
        "# scores_list = []\n",
        "# k_range = range(1, 26)\n",
        "# for k in k_range:\n",
        "#   knn = KNeighborsClassifier(n_neighbors=k)\n",
        "#   knn.fit(X_train, y_train)\n",
        "#   y_pred = knn.predict(X_test)\n",
        "#   scores[k] = metrics.accuracy_score(y_test, y_pred)\n",
        "#   scores_list.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plt.plot(k_range,scores_list) \n",
        "# plt.xlabel('Value of K for KNN')\n",
        "# plt.ylabel('Testing Accuracy')\n",
        "# \"\"\"\n",
        "\n",
        "# knn = KNeighborsClassifier(n_neighbors=10)\n",
        "# knn.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdil_W7b-N9Z"
      },
      "source": [
        "### Next, we will create our `predict_iris()` function with a `@anvil.server.callable` decorator. The decorator makes the function callable from our Anvil app. \n",
        "Add the following code to the next cell:\n",
        "```\n",
        "@anvil.server.callable\n",
        "def predict_iris(sepal_length, sepal_width, petal_length, petal_width):\n",
        "  classification = knn.predict([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "  return iris.target_names[classification][0]\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqnD8FxIJzi3",
        "outputId": "96b88644-a648-4e2c-babf-77ccc708060e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A18AWWKUJ39I"
      },
      "outputs": [],
      "source": [
        "# 모듈 호출\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import requests\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os\n",
        "from datetime import date\n",
        "import glob\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "import anvil.server\n",
        "import anvil.media\n",
        "import anvil.tables as tables\n",
        "from anvil.tables import app_tables\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCIex-NbJ8Bz"
      },
      "outputs": [],
      "source": [
        "# img_path = '/content/drive/MyDrive/Final_Project/구세은/{}'.format(date)\n",
        "# img_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8aUIX7s0ejJ"
      },
      "outputs": [],
      "source": [
        "## for FaterRCNN\n",
        "# DIR_TEST = '/content/drive/MyDrive/Final_Project/구세은/test_img'\n",
        "WEIGHTS_FILE = '/content/drive/MyDrive/Final_Project/FasterRCNN/fasterrcnn_resnet50_fpn.pth'\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX-N3kxVK9gm",
        "outputId": "e85d3076-c461-44c7-c0b8-d1b5e20f21a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Final_Project/구세은/model/dryscalp_resnet1.h5',\n",
              " '/content/drive/MyDrive/Final_Project/구세은/model/erythema_resnet.h5',\n",
              " '/content/drive/MyDrive/Final_Project/구세은/model/folliculitis_resnet.h5',\n",
              " '/content/drive/MyDrive/Final_Project/구세은/model/dandruff_resnet.h5',\n",
              " '/content/drive/MyDrive/Final_Project/구세은/model/oilyscalp_resnet.h5',\n",
              " '/content/drive/MyDrive/Final_Project/구세은/model/hairloss_resnet.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "## for CNN\n",
        "model_path ='/content/drive/MyDrive/Final_Project/구세은/model'\n",
        "glob.glob(model_path + '/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvruEddg8Bmi"
      },
      "outputs": [],
      "source": [
        "shampoo = pd.read_csv('/content/drive/MyDrive/Final_Project/구세은/shampoo_final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SJiPADFKlsu"
      },
      "outputs": [],
      "source": [
        "# survey = [0,2,2,2,1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8befYdayKGwP"
      },
      "outputs": [],
      "source": [
        "# images_path = glob.glob(img_path + '/*.jpg')\n",
        "# num_img = len(images_path)\n",
        "\n",
        "# if num_img != 4:\n",
        "#   raise Exception('Need 4 imges to process!!')\n",
        "#   raise UserWarning('Exit Early')\n",
        "# else:\n",
        "#   print('good to go')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChnTYxx3-MRt"
      },
      "outputs": [],
      "source": [
        "# @anvil.server.callable\n",
        "# def scalp_score(img_path, model_path):\n",
        "#   out = []\n",
        "#   img_folder_paths = glob.glob(img_path + '/*.jpg')\n",
        "#   model_paths = glob.glob(model_path + '/*')\n",
        "#   for i in img_folder_paths:\n",
        "#     image_name = i[-5]\n",
        "#     image = cv2.imread(i)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     image = cv2.resize(image,(224,224))\n",
        "#     image = np.array(image)*1./255\n",
        "#     image = image.reshape(1, 224,224,3)\n",
        "#     for model in model_paths:\n",
        "#       model_name = model.split('/')[-1]\n",
        "#       model_name = model_name.split('_')[0]\n",
        "#       model = load_model(model, compile = False)  \n",
        "#       prediction =model.predict(image)\n",
        "#       max = np.argmax(prediction)\n",
        "#       out.append([image_name, model_name, max])\n",
        "#   out = pd.DataFrame(out, columns = ['image_name', 'model_name', 'predict'])\n",
        "#   mean = out.groupby(by='model_name').mean().reset_index()\n",
        "#   print(mean)\n",
        "#   return(mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNtQwMMd43KG"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "class WheatTestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, image_dir, transforms=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.image_ids = dataframe['image_id'].unique()\n",
        "        self.df = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "\n",
        "        image_id = self.image_ids[index]\n",
        "        records = self.df[self.df['image_id'] == image_id]\n",
        "\n",
        "        image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "\n",
        "        if self.transforms:\n",
        "            sample = {\n",
        "                'image': image,\n",
        "            }\n",
        "            sample = self.transforms(**sample)\n",
        "            image = sample['image']\n",
        "\n",
        "        return image, image_id\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.image_ids.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tXGzqJ045Nr"
      },
      "outputs": [],
      "source": [
        "# Albumentations\n",
        "@anvil.server.callable\n",
        "def get_test_transform():\n",
        "    return A.Compose([\n",
        "        # A.Resize(512, 512),\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXK_iMD951r3"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def format_prediction_string(boxes, scores):\n",
        "    pred_strings = []\n",
        "    for j in zip(scores, boxes):\n",
        "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
        "\n",
        "    return \" \".join(pred_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "V-C1c8cz50PE",
        "outputId": "9c704ec2-3011-4f43-92d5-072a297bef1d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f8f049df7e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWheatTestDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIR_TEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_test_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m test_data_loader = DataLoader(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
          ]
        }
      ],
      "source": [
        "# def collate_fn(batch):\n",
        "#     return tuple(zip(*batch))\n",
        "\n",
        "# test_dataset = WheatTestDataset(test_df, DIR_TEST, get_test_transform())\n",
        "\n",
        "# test_data_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=10,\n",
        "#     shuffle=False,\n",
        "#     num_workers=0,\n",
        "#     drop_last=False,\n",
        "#     collate_fn=collate_fn\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnkzbAwpb6FV"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def scalp_score(img1, img2, img3, img4, q1,q2,q3,q4,q5,q6, name, datetime):\n",
        "  global model_path, WEIGHTS_FILE\n",
        "  \n",
        "  # today = date.today()\n",
        "  # date = today.strftime('%y_%m_%d')\n",
        "  date = datetime.strftime(\"%y-%m-%d\")\n",
        "  \n",
        "  #fasterRCNN 파일 만들기\n",
        "  DIR_TEST = '/content/drive/MyDrive/Final_Project/구세은/{}'.format(date)\n",
        "  os.makedirs(DIR_TEST, exist_ok=True)  #덮어쓰기 가능하려면  True\n",
        "\n",
        "  #IMAGE CNN\n",
        "  out = []\n",
        "  survey = [q1,q2,q3,q4,q5,q6]\n",
        "  survey = list(map(int, survey))\n",
        "  # img_folder_paths = glob.glob(img_path + '/*.jpg')\n",
        "  model_paths = glob.glob(model_path + '/*')\n",
        "  image_name = 'img1'\n",
        "  with anvil.media.TempFile(img1) as filename:\n",
        "    image = cv2.imread(filename)\n",
        "  \n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite(DIR_TEST+'/{}.jpg'.format(image_name), image)\n",
        "  # image.save(DIR_TEST+'/{}.jpg'.format(image_name))\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.array(image)*1./255\n",
        "  image = image.reshape(1, 224,224,3)\n",
        "  for model in model_paths:\n",
        "      model_name = model.split('/')[-1]\n",
        "      model_name = model_name.split('_')[0]\n",
        "      model = load_model(model, compile = False)  \n",
        "      prediction =model.predict(image)\n",
        "      max = np.argmax(prediction)\n",
        "      out.append([image_name, model_name, max])\n",
        "\n",
        "  with anvil.media.TempFile(img2) as filename:\n",
        "      image = cv2.imread(filename)\n",
        "  image_name = 'img2'\n",
        "  \n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite(DIR_TEST+'/{}.jpg'.format(image_name), image)\n",
        "  # image.save(DIR_TEST+'/{}.jpg'.format(image_name))\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.array(image)*1./255\n",
        "  image = image.reshape(1, 224,224,3)\n",
        "  for model in model_paths:\n",
        "      model_name = model.split('/')[-1]\n",
        "      model_name = model_name.split('_')[0]\n",
        "      model = load_model(model, compile = False)  \n",
        "      prediction =model.predict(image)\n",
        "      max = np.argmax(prediction)\n",
        "      out.append([image_name, model_name, max])\n",
        "\n",
        "  with anvil.media.TempFile(img3) as filename:\n",
        "    image = cv2.imread(filename)\n",
        "  image_name = 'img3'\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite(DIR_TEST+'/{}.jpg'.format(image_name), image)\n",
        "  # image.save(DIR_TEST+'/{}.jpg'.format(image_name))\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.array(image)*1./255\n",
        "  image = image.reshape(1, 224,224,3)\n",
        "  for model in model_paths:\n",
        "      model_name = model.split('/')[-1]\n",
        "      model_name = model_name.split('_')[0]\n",
        "      model = load_model(model, compile = False)  \n",
        "      prediction =model.predict(image)\n",
        "      max = np.argmax(prediction)\n",
        "      out.append([image_name, model_name, max])\n",
        "\n",
        "  with anvil.media.TempFile(img4) as filename:\n",
        "      image = cv2.imread(filename)\n",
        "  image_name = 'img4'\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite(DIR_TEST+'/{}.jpg'.format(image_name), image)\n",
        "  # image.save(DIR_TEST+'/{}.jpg'.format(image_name))\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.array(image)*1./255\n",
        "  image = image.reshape(1, 224,224,3)\n",
        "  for model in model_paths:\n",
        "      model_name = model.split('/')[-1]\n",
        "      model_name = model_name.split('_')[0]\n",
        "      model = load_model(model, compile = False)  \n",
        "      prediction =model.predict(image)\n",
        "      max = np.argmax(prediction)\n",
        "      out.append([image_name, model_name, max])\n",
        "  out = pd.DataFrame(out, columns = ['image_name', 'model', 'predict'])\n",
        "  mean = out.groupby(by='model').mean().reset_index()\n",
        "  mean = mean.set_index('model')\n",
        "  predict_list = mean.predict.tolist()\n",
        "\n",
        "##FASTER RCNN\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "    test_dataset = WheatTestDataset(test_df, DIR_TEST, get_test_transform())\n",
        "\n",
        "    test_data_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=10,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        drop_last=False,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "  image_name = glob.glob(DIR_TEST+'/*')\n",
        "  image_name = list(map(lambda x: x.split('/')[-1], image_name))\n",
        "  test_df = pd.DataFrame(columns = ['image_id','PredictionString'])\n",
        "  test_df['image_id'] = image_name\n",
        "\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  num_classes = 2  # 1 class (wheat) + background\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "  model.load_state_dict(torch.load(WEIGHTS_FILE))\n",
        "  model.eval()\n",
        "  x = model.to(device)\n",
        "  detection_threshold = 0.5\n",
        "  results = []\n",
        "  test_dataset = WheatTestDataset(test_df, DIR_TEST, get_test_transform())\n",
        "  test_data_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=10,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn)\n",
        "  # import gc\n",
        "  # gc.collect()\n",
        "  # torch.cuda.empty_cache()\n",
        "  for images, image_ids in test_data_loader:\n",
        "      images = list(image.to(device) for image in images)\n",
        "      outputs = model(images)\n",
        "\n",
        "      for i, image in enumerate(images):\n",
        "          boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
        "          scores = outputs[i]['scores'].data.cpu().numpy()\n",
        "          \n",
        "          boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
        "          scores = scores[scores >= detection_threshold]\n",
        "          image_id = image_ids[i]\n",
        "          \n",
        "          boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
        "          boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
        "          \n",
        "          result = {\n",
        "              'image_id': image_id,\n",
        "              'PredictionString': format_prediction_string(boxes, scores)\n",
        "          }\n",
        "\n",
        "          \n",
        "          results.append(result)\n",
        "  test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n",
        "  pimple_count = 4 - test_df.PredictionString.str.count('')\n",
        "  rcnn = np.where(pimple_count == 0, 0, 1)\n",
        "  \n",
        "  for i in range(len(images)):\n",
        "    sample = images[i].permute(1,2,0).cpu().numpy()\n",
        "    boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
        "    scores = outputs[i]['scores'].data.cpu().numpy()\n",
        "    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "    for box in boxes:\n",
        "      cv2.rectangle(sample,\n",
        "                    (box[0], box[1]),\n",
        "                    (box[2], box[3]),\n",
        "                    (220, 0, 0), 2)\n",
        "      \n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(sample)\n",
        "    # plt.savefig(r\"C:\\Users\\Andrea\\Desktop\\newimage.jpg\", bbox_inches='tight', pad_inches=0)\n",
        "    plt.savefig(DIR_TEST+'/{}.jpg'.format(i))\n",
        "    globals()['rcnn{}'.format(i)] = anvil.media.from_file(DIR_TEST+'/{}.jpg'.format(i))\n",
        "  \n",
        "  ###DX ALGORITHM\n",
        "\n",
        "  scalp_type = np.where(survey[0] >survey[1], '건성', \n",
        "                      np.where(survey[0] < survey[1],'지성', '중성')).tolist()\n",
        "  scalp_type2 = np.where(scalp_type == '건성', '악건성',\n",
        "                       np.where(scalp_type == '지성', '악지성', '중성')).tolist()\n",
        "  scalp_score = np.where (scalp_type == 0, 0, round((mean.predict.dryscalp + mean.predict.oilyscalp )/2, 1)).tolist()                   \n",
        "  hairloss_score = round(np.mean([mean.predict.hairloss  , min(survey[4], survey[5])]),1)\n",
        "  sensitivity_score = round(np.mean([mean.predict.erythema, survey[2] ]),1)\n",
        "  dandruff_score = round(np.mean([mean.predict.dandruff, mean.predict.folliculitis]),1)\n",
        "  # pimple = np.where(frcnn == 1, 3, np.nan).tolist()\n",
        "  folliculitis_score = round(np.nanmean([mean.predict.folliculitis, survey[3], mean.predict.erythema, pimple]),1) #pimple 제외\n",
        "  final_list = [scalp_score, hairloss_score, sensitivity_score, dandruff_score, folliculitis_score]\n",
        "  rec_list =[i for i, x in enumerate(final_list) if x >=2]\n",
        "  final_index = [scalp_type2, '탈모', '민감성 두피', '비듬', '두피염' ]\n",
        "  final_index2 = [scalp_type, '탈모', '민감성', '비듬', '두피염' ]\n",
        "  final_keyword = list(map(lambda x: final_index[x], rec_list))\n",
        "  final_keyword2 = ', '.join(final_keyword)\n",
        "  final_keyword3 = list(map(lambda x: final_index2[x], rec_list))\n",
        "  final_keyword3 = ', '.join(final_keyword3)\n",
        "\n",
        "\n",
        "\n",
        "  plt.rc('font', family='NanumBarunGothic')\n",
        "  markers = [0,1,2,3]\n",
        "  labels = np.array(final_index)\n",
        "  angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False)\n",
        "  stats = np.concatenate((final_list,[final_list[0]]))\n",
        "  angles = np.concatenate((angles,[angles[0]]))\n",
        "\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "  ax = fig.add_subplot(111, polar=True)\n",
        "  ax.plot(angles, stats, 'o-', linewidth=2)\n",
        "  ax.fill(angles, stats, alpha=0.25)\n",
        "  ax.set_thetagrids(angles * 180/np.pi, labels)\n",
        "  plt.yticks(markers)\n",
        "  ax.grid(True)\n",
        "  fig.savefig(\"/content/drive/MyDrive/Final_Project/구세은/{}_{}_radarchart.png\".format(name, date))\n",
        "  plt.show()\n",
        "\n",
        "  send_image = anvil.media.from_file(\"/content/drive/MyDrive/Final_Project/구세은/{}_{}_radarchart.png\".format(name, date))\n",
        "  final_list = ','.join(str(item) for item in final_list)\n",
        "  predict_list = ','.join(str(item) for item in predict_list)\n",
        "\n",
        "  return final_list, predict_list, scalp_type, final_keyword2, final_keyword3, send_image, pimple_count, rcnn1, rcnn2, rcnn3, rcnn4\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHe8y7s0xoJy"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def import_csv_data(file):\n",
        "  with open(file, \"r\") as f:\n",
        "    df = pd.read_csv(f)\n",
        "    for d in df.to_dict(orient=\"records\"):\n",
        "      # d is now a dict of {columnname -> value} for this row\n",
        "      # We use Python's **kwargs syntax to pass the whole dict as\n",
        "      # keyword arguments\n",
        "      app_tables.product.add_row(**d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOoaJ4K6NvK4"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def recommend(final_keyword, datetime) :\n",
        "    final_keyword = final_keyword.split(', ')\n",
        "    result = shampoo[shampoo['spec_list'].apply(lambda words: all(word in words for word in final_keyword))]\n",
        "    result = result[result['rate'] > 4.6]\n",
        "    result.sort_values(['rate','opinion'], ascending = False, ignore_index = True, inplace = True)\n",
        "    # result = result.sort_values(by = 'price', ascending = False, ignore_index = True)\n",
        "    result10 = result[:10] \n",
        "    result10['datetime'] = datetime\n",
        "    result_csv = result10.to_csv('result_10.csv')\n",
        "    import_csv_data('result_10.csv')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5j8bWje09QI"
      },
      "outputs": [],
      "source": [
        "# DIR_TEST = '/content/drive/MyDrive/Final_Project/구세은/{}'.format(date)\n",
        "# DIR_TEST\n",
        "# os.makedirs(DIR_TEST, exist_ok=True)  #덮어쓰기 가능하려면  True\n",
        "# print(\"{} folder is created!\".format(DIR_TEST))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAqRYKusJ3dB"
      },
      "outputs": [],
      "source": [
        "# start = time.time()\n",
        "# df = scalp_score(img_path, model_path)\n",
        "# end = time.time()\n",
        "# print(f'total time(s):{end-start}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y54Z7Ano6wT4"
      },
      "source": [
        "### Finally, let's add `anvil.server.wait_forever()` function so the notebook is always available to the web app:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "JF1L5rHt6wh6",
        "outputId": "f2840e29-b419-4701-8b10-95228a9e8036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f85f9332dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8670412170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-95cac3476493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR1p147uXX0z"
      },
      "source": [
        "---\n",
        "\n",
        "## That's it, 5 simple steps to connect your notebook to your Anvil app! \n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dupi_anvil_fasterRCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}